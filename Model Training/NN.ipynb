{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voV4m0uxDxHs"
      },
      "source": [
        "# Neural Network (NN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpDZRgNc5kNV"
      },
      "source": [
        "#Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF7m4yzQ6OtT"
      },
      "source": [
        "#Taking the EDA data \n",
        "with open('EDA.pickle', 'rb') as data:\n",
        "    df = pickle.load(data)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "N8NNkqpJ7ypT",
        "outputId": "4b98acb7-0749-4c6e-b00a-8951f73e08ab"
      },
      "source": [
        "#Initial values of dataset\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># mean_0_a</th>\n",
              "      <th>mean_1_a</th>\n",
              "      <th>mean_2_a</th>\n",
              "      <th>mean_3_a</th>\n",
              "      <th>mean_4_a</th>\n",
              "      <th>mean_d_0_a</th>\n",
              "      <th>mean_d_1_a</th>\n",
              "      <th>mean_d_2_a</th>\n",
              "      <th>mean_d_3_a</th>\n",
              "      <th>mean_d_4_a</th>\n",
              "      <th>mean_d_0_a2</th>\n",
              "      <th>mean_d_1_a2</th>\n",
              "      <th>mean_d_2_a2</th>\n",
              "      <th>mean_d_3_a2</th>\n",
              "      <th>mean_d_4_a2</th>\n",
              "      <th>mean_d_5_a</th>\n",
              "      <th>mean_d_6_a</th>\n",
              "      <th>mean_d_7_a</th>\n",
              "      <th>mean_d_8_a</th>\n",
              "      <th>mean_d_9_a</th>\n",
              "      <th>mean_d_10_a</th>\n",
              "      <th>mean_d_11_a</th>\n",
              "      <th>mean_d_12_a</th>\n",
              "      <th>mean_d_13_a</th>\n",
              "      <th>mean_d_14_a</th>\n",
              "      <th>mean_d_15_a</th>\n",
              "      <th>mean_d_16_a</th>\n",
              "      <th>mean_d_17_a</th>\n",
              "      <th>mean_d_18_a</th>\n",
              "      <th>mean_d_19_a</th>\n",
              "      <th>mean_d_20_a</th>\n",
              "      <th>mean_d_21_a</th>\n",
              "      <th>mean_d_22_a</th>\n",
              "      <th>mean_d_23_a</th>\n",
              "      <th>mean_d_24_a</th>\n",
              "      <th>mean_d_25_a</th>\n",
              "      <th>mean_d_26_a</th>\n",
              "      <th>mean_d_27_a</th>\n",
              "      <th>mean_d_28_a</th>\n",
              "      <th>mean_d_29_a</th>\n",
              "      <th>...</th>\n",
              "      <th>fft_711_b</th>\n",
              "      <th>fft_712_b</th>\n",
              "      <th>fft_713_b</th>\n",
              "      <th>fft_714_b</th>\n",
              "      <th>fft_715_b</th>\n",
              "      <th>fft_716_b</th>\n",
              "      <th>fft_717_b</th>\n",
              "      <th>fft_718_b</th>\n",
              "      <th>fft_719_b</th>\n",
              "      <th>fft_720_b</th>\n",
              "      <th>fft_721_b</th>\n",
              "      <th>fft_722_b</th>\n",
              "      <th>fft_723_b</th>\n",
              "      <th>fft_724_b</th>\n",
              "      <th>fft_725_b</th>\n",
              "      <th>fft_726_b</th>\n",
              "      <th>fft_727_b</th>\n",
              "      <th>fft_728_b</th>\n",
              "      <th>fft_729_b</th>\n",
              "      <th>fft_730_b</th>\n",
              "      <th>fft_731_b</th>\n",
              "      <th>fft_732_b</th>\n",
              "      <th>fft_733_b</th>\n",
              "      <th>fft_734_b</th>\n",
              "      <th>fft_735_b</th>\n",
              "      <th>fft_736_b</th>\n",
              "      <th>fft_737_b</th>\n",
              "      <th>fft_738_b</th>\n",
              "      <th>fft_739_b</th>\n",
              "      <th>fft_740_b</th>\n",
              "      <th>fft_741_b</th>\n",
              "      <th>fft_742_b</th>\n",
              "      <th>fft_743_b</th>\n",
              "      <th>fft_744_b</th>\n",
              "      <th>fft_745_b</th>\n",
              "      <th>fft_746_b</th>\n",
              "      <th>fft_747_b</th>\n",
              "      <th>fft_748_b</th>\n",
              "      <th>fft_749_b</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.62</td>\n",
              "      <td>30.3</td>\n",
              "      <td>-356.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>26.3</td>\n",
              "      <td>1.070</td>\n",
              "      <td>0.411</td>\n",
              "      <td>-15.70</td>\n",
              "      <td>2.06</td>\n",
              "      <td>3.15</td>\n",
              "      <td>2.15</td>\n",
              "      <td>29.5</td>\n",
              "      <td>-353.0</td>\n",
              "      <td>14.40</td>\n",
              "      <td>21.5</td>\n",
              "      <td>5.98</td>\n",
              "      <td>30.7</td>\n",
              "      <td>-343.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>27.9</td>\n",
              "      <td>3.17</td>\n",
              "      <td>32.2</td>\n",
              "      <td>-368.0</td>\n",
              "      <td>15.9</td>\n",
              "      <td>36.4</td>\n",
              "      <td>7.08</td>\n",
              "      <td>28.8</td>\n",
              "      <td>-359.0</td>\n",
              "      <td>17.3</td>\n",
              "      <td>19.6</td>\n",
              "      <td>-3.8300</td>\n",
              "      <td>-1.230</td>\n",
              "      <td>-10.80000</td>\n",
              "      <td>-0.363</td>\n",
              "      <td>-6.41</td>\n",
              "      <td>-1.03</td>\n",
              "      <td>-2.780</td>\n",
              "      <td>14.60</td>\n",
              "      <td>-1.540</td>\n",
              "      <td>-14.900000</td>\n",
              "      <td>...</td>\n",
              "      <td>30.90</td>\n",
              "      <td>-24.4</td>\n",
              "      <td>-24.4</td>\n",
              "      <td>30.90</td>\n",
              "      <td>-442.0</td>\n",
              "      <td>388.0</td>\n",
              "      <td>-197.0</td>\n",
              "      <td>-197.0</td>\n",
              "      <td>388.0</td>\n",
              "      <td>-564.0</td>\n",
              "      <td>500.00</td>\n",
              "      <td>-245.00</td>\n",
              "      <td>-245.00</td>\n",
              "      <td>500.00</td>\n",
              "      <td>-88.8</td>\n",
              "      <td>214.0</td>\n",
              "      <td>-88.8</td>\n",
              "      <td>-88.8</td>\n",
              "      <td>214.0</td>\n",
              "      <td>-606.0</td>\n",
              "      <td>509.000</td>\n",
              "      <td>-261.0</td>\n",
              "      <td>-261.0</td>\n",
              "      <td>509.000</td>\n",
              "      <td>-399.0</td>\n",
              "      <td>374.0</td>\n",
              "      <td>-185.00</td>\n",
              "      <td>-185.00</td>\n",
              "      <td>374.0</td>\n",
              "      <td>74.3</td>\n",
              "      <td>23.5</td>\n",
              "      <td>20.3</td>\n",
              "      <td>20.3</td>\n",
              "      <td>23.5</td>\n",
              "      <td>-215.0</td>\n",
              "      <td>280.00</td>\n",
              "      <td>-162.00</td>\n",
              "      <td>-162.00</td>\n",
              "      <td>280.00</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.80</td>\n",
              "      <td>33.1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>25.8</td>\n",
              "      <td>22.8</td>\n",
              "      <td>6.550</td>\n",
              "      <td>1.680</td>\n",
              "      <td>2.88</td>\n",
              "      <td>3.83</td>\n",
              "      <td>-4.82</td>\n",
              "      <td>25.60</td>\n",
              "      <td>32.8</td>\n",
              "      <td>29.6</td>\n",
              "      <td>21.50</td>\n",
              "      <td>17.4</td>\n",
              "      <td>25.50</td>\n",
              "      <td>31.7</td>\n",
              "      <td>31.5</td>\n",
              "      <td>26.2</td>\n",
              "      <td>32.9</td>\n",
              "      <td>31.80</td>\n",
              "      <td>33.1</td>\n",
              "      <td>33.2</td>\n",
              "      <td>28.5</td>\n",
              "      <td>26.8</td>\n",
              "      <td>32.40</td>\n",
              "      <td>34.7</td>\n",
              "      <td>33.8</td>\n",
              "      <td>27.0</td>\n",
              "      <td>14.2</td>\n",
              "      <td>0.0342</td>\n",
              "      <td>1.100</td>\n",
              "      <td>-1.87000</td>\n",
              "      <td>-4.690</td>\n",
              "      <td>-15.40</td>\n",
              "      <td>-6.22</td>\n",
              "      <td>-0.328</td>\n",
              "      <td>-3.53</td>\n",
              "      <td>-6.980</td>\n",
              "      <td>-9.370000</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.99</td>\n",
              "      <td>-19.1</td>\n",
              "      <td>-19.1</td>\n",
              "      <td>-5.99</td>\n",
              "      <td>163.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-10.7</td>\n",
              "      <td>-10.7</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>-3.93</td>\n",
              "      <td>17.90</td>\n",
              "      <td>17.90</td>\n",
              "      <td>-3.93</td>\n",
              "      <td>112.0</td>\n",
              "      <td>-13.9</td>\n",
              "      <td>25.5</td>\n",
              "      <td>25.5</td>\n",
              "      <td>-13.9</td>\n",
              "      <td>225.0</td>\n",
              "      <td>-0.968</td>\n",
              "      <td>-27.7</td>\n",
              "      <td>-27.7</td>\n",
              "      <td>-0.968</td>\n",
              "      <td>97.4</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>40.70</td>\n",
              "      <td>40.70</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>-23.3</td>\n",
              "      <td>-21.8</td>\n",
              "      <td>-21.8</td>\n",
              "      <td>-23.3</td>\n",
              "      <td>182.0</td>\n",
              "      <td>2.57</td>\n",
              "      <td>-31.60</td>\n",
              "      <td>-31.60</td>\n",
              "      <td>2.57</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.90</td>\n",
              "      <td>29.4</td>\n",
              "      <td>-416.0</td>\n",
              "      <td>16.7</td>\n",
              "      <td>23.7</td>\n",
              "      <td>79.900</td>\n",
              "      <td>3.360</td>\n",
              "      <td>90.20</td>\n",
              "      <td>89.90</td>\n",
              "      <td>2.03</td>\n",
              "      <td>7.75</td>\n",
              "      <td>30.1</td>\n",
              "      <td>-441.0</td>\n",
              "      <td>9.89</td>\n",
              "      <td>25.3</td>\n",
              "      <td>-68.90</td>\n",
              "      <td>25.3</td>\n",
              "      <td>-481.0</td>\n",
              "      <td>-65.4</td>\n",
              "      <td>20.0</td>\n",
              "      <td>79.80</td>\n",
              "      <td>31.0</td>\n",
              "      <td>-408.0</td>\n",
              "      <td>91.9</td>\n",
              "      <td>29.5</td>\n",
              "      <td>18.80</td>\n",
              "      <td>31.1</td>\n",
              "      <td>-335.0</td>\n",
              "      <td>32.2</td>\n",
              "      <td>19.9</td>\n",
              "      <td>76.6000</td>\n",
              "      <td>4.850</td>\n",
              "      <td>39.90000</td>\n",
              "      <td>75.300</td>\n",
              "      <td>5.27</td>\n",
              "      <td>-72.00</td>\n",
              "      <td>-0.843</td>\n",
              "      <td>-33.00</td>\n",
              "      <td>-82.000</td>\n",
              "      <td>-4.200000</td>\n",
              "      <td>...</td>\n",
              "      <td>585.00</td>\n",
              "      <td>-285.0</td>\n",
              "      <td>-285.0</td>\n",
              "      <td>585.00</td>\n",
              "      <td>-94.3</td>\n",
              "      <td>183.0</td>\n",
              "      <td>-110.0</td>\n",
              "      <td>-110.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>-133.0</td>\n",
              "      <td>200.00</td>\n",
              "      <td>-72.00</td>\n",
              "      <td>-72.00</td>\n",
              "      <td>200.00</td>\n",
              "      <td>-356.0</td>\n",
              "      <td>295.0</td>\n",
              "      <td>-158.0</td>\n",
              "      <td>-158.0</td>\n",
              "      <td>295.0</td>\n",
              "      <td>-251.0</td>\n",
              "      <td>255.000</td>\n",
              "      <td>-95.7</td>\n",
              "      <td>-95.7</td>\n",
              "      <td>255.000</td>\n",
              "      <td>-177.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>-48.80</td>\n",
              "      <td>-48.80</td>\n",
              "      <td>159.0</td>\n",
              "      <td>-534.0</td>\n",
              "      <td>462.0</td>\n",
              "      <td>-233.0</td>\n",
              "      <td>-233.0</td>\n",
              "      <td>462.0</td>\n",
              "      <td>-267.0</td>\n",
              "      <td>281.00</td>\n",
              "      <td>-148.00</td>\n",
              "      <td>-148.00</td>\n",
              "      <td>281.00</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.90</td>\n",
              "      <td>31.6</td>\n",
              "      <td>-143.0</td>\n",
              "      <td>19.8</td>\n",
              "      <td>24.3</td>\n",
              "      <td>-0.584</td>\n",
              "      <td>-0.284</td>\n",
              "      <td>8.82</td>\n",
              "      <td>2.30</td>\n",
              "      <td>-1.97</td>\n",
              "      <td>17.30</td>\n",
              "      <td>32.0</td>\n",
              "      <td>-148.0</td>\n",
              "      <td>20.40</td>\n",
              "      <td>22.8</td>\n",
              "      <td>13.20</td>\n",
              "      <td>31.5</td>\n",
              "      <td>-147.0</td>\n",
              "      <td>16.9</td>\n",
              "      <td>27.7</td>\n",
              "      <td>15.70</td>\n",
              "      <td>30.7</td>\n",
              "      <td>-142.0</td>\n",
              "      <td>20.7</td>\n",
              "      <td>22.8</td>\n",
              "      <td>13.60</td>\n",
              "      <td>32.2</td>\n",
              "      <td>-135.0</td>\n",
              "      <td>21.2</td>\n",
              "      <td>23.8</td>\n",
              "      <td>4.1500</td>\n",
              "      <td>0.556</td>\n",
              "      <td>-0.35400</td>\n",
              "      <td>3.460</td>\n",
              "      <td>-4.96</td>\n",
              "      <td>1.63</td>\n",
              "      <td>1.330</td>\n",
              "      <td>-5.83</td>\n",
              "      <td>-0.298</td>\n",
              "      <td>0.000777</td>\n",
              "      <td>...</td>\n",
              "      <td>249.00</td>\n",
              "      <td>-146.0</td>\n",
              "      <td>-146.0</td>\n",
              "      <td>249.00</td>\n",
              "      <td>359.0</td>\n",
              "      <td>-146.0</td>\n",
              "      <td>13.7</td>\n",
              "      <td>13.7</td>\n",
              "      <td>-146.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>-7.64</td>\n",
              "      <td>-7.17</td>\n",
              "      <td>-7.17</td>\n",
              "      <td>-7.64</td>\n",
              "      <td>-296.0</td>\n",
              "      <td>316.0</td>\n",
              "      <td>-218.0</td>\n",
              "      <td>-218.0</td>\n",
              "      <td>316.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>-113.000</td>\n",
              "      <td>38.4</td>\n",
              "      <td>38.4</td>\n",
              "      <td>-113.000</td>\n",
              "      <td>245.0</td>\n",
              "      <td>-61.9</td>\n",
              "      <td>-5.08</td>\n",
              "      <td>-5.08</td>\n",
              "      <td>-61.9</td>\n",
              "      <td>-183.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>-243.0</td>\n",
              "      <td>-243.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>-12.40</td>\n",
              "      <td>9.53</td>\n",
              "      <td>9.53</td>\n",
              "      <td>-12.40</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28.30</td>\n",
              "      <td>31.3</td>\n",
              "      <td>45.2</td>\n",
              "      <td>27.3</td>\n",
              "      <td>24.5</td>\n",
              "      <td>34.800</td>\n",
              "      <td>-5.790</td>\n",
              "      <td>3.06</td>\n",
              "      <td>41.40</td>\n",
              "      <td>5.52</td>\n",
              "      <td>26.10</td>\n",
              "      <td>34.3</td>\n",
              "      <td>43.7</td>\n",
              "      <td>23.70</td>\n",
              "      <td>20.6</td>\n",
              "      <td>-3.87</td>\n",
              "      <td>34.1</td>\n",
              "      <td>43.7</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>22.9</td>\n",
              "      <td>59.40</td>\n",
              "      <td>26.7</td>\n",
              "      <td>60.3</td>\n",
              "      <td>64.7</td>\n",
              "      <td>26.9</td>\n",
              "      <td>32.30</td>\n",
              "      <td>30.1</td>\n",
              "      <td>33.6</td>\n",
              "      <td>31.6</td>\n",
              "      <td>27.7</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>0.276</td>\n",
              "      <td>-0.00677</td>\n",
              "      <td>33.700</td>\n",
              "      <td>-2.36</td>\n",
              "      <td>-33.30</td>\n",
              "      <td>7.640</td>\n",
              "      <td>-16.60</td>\n",
              "      <td>-41.100</td>\n",
              "      <td>-6.290000</td>\n",
              "      <td>...</td>\n",
              "      <td>18.30</td>\n",
              "      <td>-11.9</td>\n",
              "      <td>-11.9</td>\n",
              "      <td>18.30</td>\n",
              "      <td>159.0</td>\n",
              "      <td>-18.2</td>\n",
              "      <td>-25.6</td>\n",
              "      <td>-25.6</td>\n",
              "      <td>-18.2</td>\n",
              "      <td>194.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>-54.50</td>\n",
              "      <td>-54.50</td>\n",
              "      <td>32.70</td>\n",
              "      <td>154.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>-56.4</td>\n",
              "      <td>-56.4</td>\n",
              "      <td>26.4</td>\n",
              "      <td>252.0</td>\n",
              "      <td>9.940</td>\n",
              "      <td>-37.4</td>\n",
              "      <td>-37.4</td>\n",
              "      <td>9.940</td>\n",
              "      <td>172.0</td>\n",
              "      <td>15.9</td>\n",
              "      <td>-7.25</td>\n",
              "      <td>-7.25</td>\n",
              "      <td>15.9</td>\n",
              "      <td>114.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>38.1</td>\n",
              "      <td>38.1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>-17.60</td>\n",
              "      <td>23.90</td>\n",
              "      <td>23.90</td>\n",
              "      <td>-17.60</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2549 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   # mean_0_a  mean_1_a  mean_2_a  ...  fft_748_b  fft_749_b     label\n",
              "0        4.62      30.3    -356.0  ...    -162.00     280.00  NEGATIVE\n",
              "1       28.80      33.1      32.0  ...     -31.60       2.57   NEUTRAL\n",
              "2        8.90      29.4    -416.0  ...    -148.00     281.00  POSITIVE\n",
              "3       14.90      31.6    -143.0  ...       9.53     -12.40  POSITIVE\n",
              "4       28.30      31.3      45.2  ...      23.90     -17.60   NEUTRAL\n",
              "\n",
              "[5 rows x 2549 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D9cqOhB70JI",
        "outputId": "d0672c73-921b-464d-ea59-459d1410658b"
      },
      "source": [
        "#Shape of dataset\n",
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2132, 2549)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eGI_Ie771dy"
      },
      "source": [
        "#Lable mapping\n",
        "label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyjMUN9b719V"
      },
      "source": [
        "#Function for creating train test split\n",
        "def preprocess_inputs(df):\n",
        "    df = df.copy()\n",
        "    \n",
        "    df['label'] = df['label'].replace(label_mapping)\n",
        "    \n",
        "    y = df['label'].copy()\n",
        "    X = df.drop('label', axis=1).copy()\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JtAKAER73dd"
      },
      "source": [
        "X_train, X_test, y_train, y_test = preprocess_inputs(df)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZP83JoU75oI",
        "outputId": "920c462e-e972-436f-8aed-9c826095feb7"
      },
      "source": [
        "print('Shape of Training Dataset:',X_train.shape)\n",
        "print('Shape of Testing Dataset:',X_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Training Dataset: (1492, 2548)\n",
            "Shape of Testing Dataset: (640, 2548)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLD9GCKf764m",
        "outputId": "f687ab10-d76a-458a-8119-40c35e37da4a"
      },
      "source": [
        "#Modeling\n",
        "Inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
        "\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(Inputs)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "Outputs = tf.keras.layers.Dense(3,activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=Inputs, outputs=Outputs)\n",
        "print(model.summary())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 2548)]            0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                163136    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 167,491\n",
            "Trainable params: 167,491\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Esyp0J9hiz"
      },
      "source": [
        "#Model Compiling\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caJ23End9z6n",
        "outputId": "79a4e8cf-1679-41e5-8560-3bf2dfc1edd1"
      },
      "source": [
        "#fitting the model\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.3,\n",
        "    batch_size=20,\n",
        "    epochs=50,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 26890626662400.0000 - accuracy: 0.5316 - val_loss: 81156066246656.0000 - val_accuracy: 0.5312\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 17585825382400.0000 - accuracy: 0.5182 - val_loss: 47069247045632.0000 - val_accuracy: 0.5603\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 13383706345472.0000 - accuracy: 0.5307 - val_loss: 21480658173952.0000 - val_accuracy: 0.4955\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 32715550228480.0000 - accuracy: 0.4856 - val_loss: 165068025102336.0000 - val_accuracy: 0.5134\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 22641027055616.0000 - accuracy: 0.4962 - val_loss: 3295269617664.0000 - val_accuracy: 0.4554\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 7003505164288.0000 - accuracy: 0.5144 - val_loss: 76036440064000.0000 - val_accuracy: 0.5536\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 28733203283968.0000 - accuracy: 0.5575 - val_loss: 73171671711744.0000 - val_accuracy: 0.5781\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 76058426605568.0000 - accuracy: 0.5220 - val_loss: 258087051067392.0000 - val_accuracy: 0.5223\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 58308870275072.0000 - accuracy: 0.5096 - val_loss: 116339985350656.0000 - val_accuracy: 0.5469\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 21179928674304.0000 - accuracy: 0.5153 - val_loss: 161246645059584.0000 - val_accuracy: 0.5246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZD7FQIv-7mW"
      },
      "source": [
        "#Prediction \n",
        "nn_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(X_test))))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OapoxUo4-UUC",
        "outputId": "7ba89a98-52ee-4f01-d62a-e314abce7df7"
      },
      "source": [
        "#Train Set Accuracy\n",
        "model_train_acc = model.evaluate(X_train, y_train, verbose=0)[1]\n",
        "print(\"Training Accuracy: {:.3f}%\".format(model_train_acc * 100))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 45.509%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPfqm28Q97mx",
        "outputId": "a945c8e6-620a-487d-9c0a-d6aba20908f1"
      },
      "source": [
        "#Test Set Accuracy\n",
        "model_test_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(\"Test Accuracy: {:.3f}%\".format(model_test_acc * 100))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 40.156%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBQ4R-ke-TMV",
        "outputId": "32c2a629-cdfc-4498-856b-c5c37412b65e"
      },
      "source": [
        "# Classification report\n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test, nn_pred, target_names=label_mapping.keys()))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.67      0.44      0.53       201\n",
            "     NEUTRAL       0.44      0.05      0.09       231\n",
            "    POSITIVE       0.33      0.75      0.46       208\n",
            "\n",
            "    accuracy                           0.40       640\n",
            "   macro avg       0.48      0.41      0.36       640\n",
            "weighted avg       0.48      0.40      0.35       640\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "TTjZbiAq-1TX",
        "outputId": "a49f9ee8-d8f5-4a4b-b8df-813a822fef1a"
      },
      "source": [
        "#Plotting the confusion matrix\n",
        "plt.figure(figsize=(8, 8))\n",
        "cm = confusion_matrix(y_test, nn_pred)\n",
        "sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\n",
        "plt.xticks(np.arange(3) + 0.5, label_mapping.keys())\n",
        "plt.yticks(np.arange(3) + 0.5, label_mapping.keys())\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(\"ConfusionMatrix_NN.png\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3T_cd3zAWtT"
      },
      "source": [
        "#Creating dictionary for storing the accuracy details\n",
        "d = {\n",
        "     'Model': 'Neural Network',\n",
        "     'Training Set Accuracy': model_train_acc,\n",
        "     'Test Set Accuracy':model_test_acc\n",
        "}\n",
        "\n",
        "#Creating Data Frame \n",
        "df_models_nn = pd.DataFrame(d, index=[0])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "uRaV1vWtAv1F",
        "outputId": "dd07e0c1-ddae-4646-9c51-2976e70df3f7"
      },
      "source": [
        "df_models_nn"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training Set Accuracy</th>\n",
              "      <th>Test Set Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Neural Network</td>\n",
              "      <td>0.455094</td>\n",
              "      <td>0.401563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Model  Training Set Accuracy  Test Set Accuracy\n",
              "0  Neural Network               0.455094           0.401563"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Z2TWBUBJeE"
      },
      "source": [
        "#Creating pickle files for further use\n",
        "model.save('../Models/best_nn.h5')\n",
        "    \n",
        "with open('../Models/df_models_nn.pickle', 'wb') as output:\n",
        "    pickle.dump(df_models_nn, output)"
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}